{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f7ede11",
   "metadata": {},
   "source": [
    "# Advanced Prompt Engineering Techniques\n",
    "\n",
    "In this notebook, we'll explore various prompt engineering techniques that can significantly improve the performance of Large Language Models (LLMs). Prompt engineering is the art and science of designing effective prompts to elicit the best possible responses from LLMs.\n",
    "\n",
    "We'll cover the following techniques:\n",
    "1. Zero-shot Prompting\n",
    "2. Few-shot Prompting\n",
    "3. Chain of Thought (CoT) Prompting\n",
    "4. Role Playing\n",
    "\n",
    "Let's start by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0157913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from google import genai\n",
    "\n",
    "# Load environment variables from .env file (if you have any API keys)\n",
    "load_dotenv()\n",
    "\n",
    "# Configure the Google Generative AI API with your API key\n",
    "client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16734a1d",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Let's create some utility functions to make it easier to interact with the language model and display results consistently throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad498cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gemini_response(prompt, model=\"gemini-2.0-flash\"):\n",
    "    \"\"\"\n",
    "    Get a response from Google's Gemini model\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The prompt to send to the model\n",
    "        model (str): The model to use (default: gemini-pro)\n",
    "        \n",
    "    Returns:\n",
    "        str: The model's response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Configure the model\n",
    "        generation_config = {\n",
    "            \"temperature\": 0.2,\n",
    "            \"top_p\": 0.95,\n",
    "            \"top_k\": 40,\n",
    "            \"max_output_tokens\": 1024,\n",
    "        }\n",
    "        \n",
    "        \n",
    "        # Generate the response\n",
    "        response = client.models.generate_content(\n",
    "            contents=prompt,\n",
    "            model=model,\n",
    "            config=generation_config,\n",
    "            )\n",
    "        \n",
    "        # Return the response text\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def display_prompt_response(prompt, response, technique=\"\"):\n",
    "    \"\"\"\n",
    "    Display the prompt and response in a formatted way\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The prompt sent to the model\n",
    "        response (str): The model's response\n",
    "        technique (str): The prompt engineering technique used\n",
    "    \"\"\"\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"TECHNIQUE: {technique}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"\\nüìù PROMPT:\")\n",
    "    print(f\"{'-'*80}\")\n",
    "    print(prompt)\n",
    "    print(f\"{'-'*80}\")\n",
    "    print(\"\\nü§ñ RESPONSE:\")\n",
    "    print(f\"{'-'*80}\")\n",
    "    print(response)\n",
    "    print(f\"{'-'*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e861b9",
   "metadata": {},
   "source": [
    "## 1. Zero-shot Prompting\n",
    "\n",
    "Zero-shot prompting is a technique where we ask the model to perform a task without providing any examples. This approach relies on the model's pre-trained knowledge to understand and complete the task.\n",
    "\n",
    "**Key characteristics:**\n",
    "- No examples are provided\n",
    "- The model relies entirely on its pre-trained knowledge\n",
    "- Clear and specific instructions are crucial\n",
    "- Works best for simple tasks or when the model has strong prior knowledge\n",
    "\n",
    "Let's see some examples of zero-shot prompting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84eb55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Classification task with zero-shot\n",
    "zero_shot_classification = \"\"\"\n",
    "Classify the following text into one of these categories: Business, Technology, Sports, Politics, Entertainment.\n",
    "\n",
    "Text: \"Apple announces new iPhone with revolutionary AI capabilities and improved battery life.\"\n",
    "Category:\n",
    "\"\"\"\n",
    "\n",
    "# Example 2: Translation task with zero-shot\n",
    "zero_shot_translation = \"\"\"\n",
    "Translate the following English text to French:\n",
    "\n",
    "\"The artificial intelligence revolution is transforming how we work and live.\"\n",
    "\"\"\"\n",
    "\n",
    "# Example 3: Text summarization with zero-shot\n",
    "zero_shot_summarization = \"\"\"\n",
    "Summarize the following paragraph in one sentence:\n",
    "\n",
    "The James Webb Space Telescope, launched in December 2021, is the largest optical telescope in space. It conducts infrared astronomy and can view objects too old, distant, or faint for the Hubble Space Telescope. Its improved infrared resolution and sensitivity allow it to view objects too early in the universe's history for Hubble to see, which is expected to enable a broad range of investigations across many fields of astronomy and cosmology.\n",
    "\"\"\"\n",
    "\n",
    "# Let's test these zero-shot prompts\n",
    "# Uncomment to run:\n",
    "response1 = get_gemini_response(zero_shot_classification)\n",
    "display_prompt_response(zero_shot_classification, response1, \"Zero-shot Classification\")\n",
    "\n",
    "# response2 = get_gemini_response(zero_shot_translation)\n",
    "# display_prompt_response(zero_shot_translation, response2, \"Zero-shot Translation\")\n",
    "\n",
    "# response3 = get_gemini_response(zero_shot_summarization)\n",
    "# display_prompt_response(zero_shot_summarization, response3, \"Zero-shot Summarization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60b71d8",
   "metadata": {},
   "source": [
    "## 2. Few-shot Prompting\n",
    "\n",
    "Few-shot prompting involves providing the model with a few examples of the task before asking it to perform a similar task. This technique helps the model understand the pattern and expected output format.\n",
    "\n",
    "**Key characteristics:**\n",
    "- Includes a small number of examples (typically 2-5)\n",
    "- Examples demonstrate the expected input-output pattern\n",
    "- Helps the model understand the task's structure\n",
    "- Improves performance on tasks where zero-shot might struggle\n",
    "- Format consistency between examples and the final question is important\n",
    "\n",
    "Let's see some examples of few-shot prompting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Sentiment analysis with few-shot learning\n",
    "few_shot_sentiment = \"\"\"\n",
    "I'll provide some examples of sentiment analysis, then I want you to classify a new text.\n",
    "\n",
    "Text: \"The food was terrible and the service was even worse.\"\n",
    "Sentiment: Negative\n",
    "\n",
    "Text: \"I had a great time at the concert, the band was amazing!\"\n",
    "Sentiment: Positive\n",
    "\n",
    "Text: \"The hotel room was clean, but the wifi didn't work properly.\"\n",
    "Sentiment: Mixed\n",
    "\n",
    "Text: \"The new smartphone has impressive features but is quite expensive.\"\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "# Example 2: Named entity recognition with few-shot\n",
    "few_shot_ner = \"\"\"\n",
    "Here are some examples of identifying organizations in text:\n",
    "\n",
    "Text: \"Apple is planning to open a new store in Mumbai next year.\"\n",
    "Organization: Apple\n",
    "\n",
    "Text: \"Google and Microsoft announced a new partnership yesterday.\"\n",
    "Organizations: Google, Microsoft\n",
    "\n",
    "Text: \"The World Health Organization issued new guidelines for pandemic preparedness.\"\n",
    "Organization: World Health Organization\n",
    "\n",
    "Text: \"Tesla has revealed its latest electric vehicle model at a special event in Austin.\"\n",
    "Organization:\n",
    "\"\"\"\n",
    "\n",
    "# Example 3: Custom classification with few-shot\n",
    "few_shot_custom = \"\"\"\n",
    "Here are some examples of classifying customer feedback by department:\n",
    "\n",
    "Feedback: \"The website kept crashing when I tried to checkout.\"\n",
    "Department: Technical Support\n",
    "\n",
    "Feedback: \"The representative was very helpful and solved my issue quickly.\"\n",
    "Department: Customer Service\n",
    "\n",
    "Feedback: \"My package arrived damaged and some items were missing.\"\n",
    "Department: Shipping\n",
    "\n",
    "Feedback: \"I was charged twice for my subscription.\"\n",
    "Department:\n",
    "\"\"\"\n",
    "\n",
    "# Let's test these few-shot prompts\n",
    "# Uncomment to run:\n",
    "response4 = get_gemini_response(few_shot_sentiment)\n",
    "display_prompt_response(few_shot_sentiment, response4, \"Few-shot Sentiment Analysis\")\n",
    "\n",
    "# response5 = get_gemini_response(few_shot_ner)\n",
    "# display_prompt_response(few_shot_ner, response5, \"Few-shot Named Entity Recognition\")\n",
    "\n",
    "# response6 = get_gemini_response(few_shot_custom)\n",
    "# display_prompt_response(few_shot_custom, response6, \"Few-shot Custom Classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e92e96",
   "metadata": {},
   "source": [
    "## 3. Chain of Thought (CoT) Prompting\n",
    "\n",
    "Chain of Thought prompting is a technique that encourages the model to show its reasoning process step by step before arriving at the final answer. This approach often improves the accuracy of complex reasoning tasks.\n",
    "\n",
    "**Key characteristics:**\n",
    "- Explicitly asks the model to \"think step by step\"\n",
    "- Breaks down complex problems into smaller, more manageable steps\n",
    "- Can be combined with few-shot examples to demonstrate the reasoning process\n",
    "- Particularly effective for mathematical problems, logical reasoning, and multi-step tasks\n",
    "- Helps the model avoid jumping to incorrect conclusions\n",
    "\n",
    "Let's see some examples of Chain of Thought prompting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209fa440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Zero-shot Chain of Thought (adding \"Let's think step by step\")\n",
    "zero_shot_cot = \"\"\"\n",
    "A store is having a 25% off sale. If a shirt originally costs $60 and jeans originally cost $90, how much would you save in total if you bought both items during the sale?\n",
    "\n",
    "Let's think step by step.\n",
    "\"\"\"\n",
    "\n",
    "# Example 2: Few-shot Chain of Thought (providing example reasoning)\n",
    "few_shot_cot = \"\"\"\n",
    "I'll solve some math problems by showing my reasoning step by step.\n",
    "\n",
    "Problem: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\n",
    "Solution: Roger starts with 5 tennis balls. He buys 2 cans of tennis balls, with 3 tennis balls per can. So he buys 2 * 3 = 6 new tennis balls. Now he has 5 + 6 = 11 tennis balls.\n",
    "\n",
    "Problem: A restaurant offers a 15% discount on the bill if you pay with cash. If your bill is $80, how much would you pay if you use cash?\n",
    "Solution: The discount is 15% of $80. 15% of 80 is 80 * 0.15 = $12. So the discount is $12. The discounted price is $80 - $12 = $68. So you would pay $68.\n",
    "\n",
    "Problem: Sarah is planning a trip to visit 3 different cities. She will spend 4 days in each city. She also spends 2 days traveling between each city. How many total days will Sarah's trip take?\n",
    "Solution:\n",
    "\"\"\"\n",
    "\n",
    "# Example 3: Complex reasoning with CoT\n",
    "complex_cot = \"\"\"\n",
    "Solve the following problem step by step: \n",
    "\n",
    "In a small town, 60% of adults work full-time, 15% work part-time, and the rest are unemployed or retired. If the town has 5,000 adults, and 20% of full-time workers and 30% of part-time workers also attend evening classes, how many adults in the town attend evening classes while also working (either full-time or part-time)?\n",
    "\n",
    "Think through this step by step.\n",
    "\"\"\"\n",
    "\n",
    "# Let's test these Chain of Thought prompts\n",
    "# Uncomment to run:\n",
    "response7 = get_gemini_response(zero_shot_cot)\n",
    "display_prompt_response(zero_shot_cot, response7, \"Zero-shot Chain of Thought\")\n",
    "\n",
    "# response8 = get_gemini_response(few_shot_cot)\n",
    "# display_prompt_response(few_shot_cot, response8, \"Few-shot Chain of Thought\")\n",
    "\n",
    "# response9 = get_gemini_response(complex_cot)\n",
    "# display_prompt_response(complex_cot, response9, \"Complex Reasoning with Chain of Thought\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af56be32",
   "metadata": {},
   "source": [
    "## 4. Role Playing Prompting\n",
    "\n",
    "Role Playing prompting involves asking the model to adopt a specific persona or role when generating responses. By giving the model a specific role to play, you can guide its responses to align with the expertise, tone, and perspective of that role.\n",
    "\n",
    "**Key characteristics:**\n",
    "- Assigns a specific identity or role to the model\n",
    "- Can include expertise level, personality traits, or professional background\n",
    "- Often improves responses for specialized knowledge domains\n",
    "- Helps maintain a consistent tone and perspective\n",
    "- Can be combined with other techniques like Chain of Thought\n",
    "\n",
    "Let's see some examples of Role Playing prompting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0637a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Expert role for technical explanation\n",
    "expert_role = \"\"\"\n",
    "You are an experienced quantum physicist explaining quantum computing concepts to a computer science graduate student. \n",
    "\n",
    "Explain quantum superposition and entanglement, and how they enable quantum computing to solve certain problems more efficiently than classical computing.\n",
    "\"\"\"\n",
    "\n",
    "# Example 2: Historical figure role\n",
    "historical_role = \"\"\"\n",
    "You are Ada Lovelace, the world's first computer programmer who worked with Charles Babbage on the Analytical Engine in the 1800s.\n",
    "\n",
    "What would you think about modern artificial intelligence and machine learning? Respond in the style and with the perspective that Ada Lovelace might have had.\n",
    "\"\"\"\n",
    "\n",
    "# Example 3: Professional role with specific task\n",
    "professional_role = \"\"\"\n",
    "You are a senior marketing strategist for a sustainable fashion brand targeting environmentally conscious consumers aged 25-40.\n",
    "\n",
    "Develop a brief marketing strategy for launching a new line of clothing made from recycled ocean plastic. Include key messaging points, potential channels for promotion, and how to address potential consumer concerns.\n",
    "\"\"\"\n",
    "\n",
    "# Let's test these Role Playing prompts\n",
    "# Uncomment to run:\n",
    "# response10 = get_gemini_response(expert_role)\n",
    "# display_prompt_response(expert_role, response10, \"Expert Role - Quantum Physicist\")\n",
    "\n",
    "# response11 = get_gemini_response(historical_role)\n",
    "# display_prompt_response(historical_role, response11, \"Historical Role - Ada Lovelace\")\n",
    "\n",
    "# response12 = get_gemini_response(professional_role)\n",
    "# display_prompt_response(professional_role, response12, \"Professional Role - Marketing Strategist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece01cfc",
   "metadata": {},
   "source": [
    "## Comparing Prompt Engineering Techniques\n",
    "\n",
    "Let's create a comparison of the various prompt engineering techniques we've explored:\n",
    "\n",
    "| Technique | Best Used For | Advantages | Limitations |\n",
    "|-----------|---------------|------------|-------------|\n",
    "| Zero-shot | Simple tasks, standard operations | No examples needed, minimal prompt | May struggle with complex or ambiguous tasks |\n",
    "| Few-shot | Tasks with specific patterns or formats | Improves accuracy through example learning | Requires careful selection of representative examples |\n",
    "| Chain of Thought | Complex reasoning, multi-step problems | Improves accuracy for logical/mathematical tasks | Creates longer outputs, may introduce verbosity |\n",
    "| Role Playing | Domain-specific knowledge, consistent tone | Specialized knowledge, consistent perspective | May limit general knowledge if role is too narrow |\n",
    "\n",
    "## Combining Techniques\n",
    "\n",
    "These techniques are not mutually exclusive and can be combined for even better results. For example:\n",
    "\n",
    "1. **Few-shot Chain of Thought**: Provide examples that demonstrate step-by-step reasoning, then ask the model to solve a new problem using the same approach.\n",
    "2. **Role Playing with Chain of Thought**: Ask the model to adopt a specific role and then think through a problem step by step from that perspective.\n",
    "3. **Zero-shot with Role Playing**: Give the model a role but no examples, relying on its pre-trained knowledge within that role's perspective.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Prompt engineering is both an art and a science. The effectiveness of different techniques depends on:\n",
    "\n",
    "- The specific task you're trying to accomplish\n",
    "- The complexity of the problem\n",
    "- The capabilities of the underlying model\n",
    "- The clarity and structure of your prompt\n",
    "\n",
    "Experimenting with different approaches and combinations of techniques will help you find the most effective way to communicate with language models for your specific use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b71e17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical Exercise: Compare techniques on the same task\n",
    "\n",
    "# Let's define a task that we'll approach with different prompt engineering techniques\n",
    "task_description = \"Explain the concept of machine learning bias to a non-technical audience.\"\n",
    "\n",
    "# Zero-shot approach\n",
    "zero_shot_prompt = f\"\"\"\n",
    "{task_description}\n",
    "\"\"\"\n",
    "\n",
    "# Few-shot approach\n",
    "few_shot_prompt = f\"\"\"\n",
    "Here are some examples of explanations for technical concepts:\n",
    "\n",
    "Technical Concept: Cloud Computing\n",
    "Explanation for Non-Technical Audience: Cloud computing is like renting space in someone else's digital garage. Instead of storing all your files and running programs on your own computer, you keep them on big computers owned by companies like Amazon or Microsoft. You access these files and programs through the internet. This saves you from buying and maintaining expensive equipment, and you can usually access your stuff from any device with internet access.\n",
    "\n",
    "Technical Concept: Encryption\n",
    "Explanation for Non-Technical Audience: Encryption is like sending a letter in a locked box. Only the person with the right key can open it and read the message inside. Even if someone intercepts the box during delivery, they can't read your message without the key. This is how your sensitive information, like credit card numbers, stays secure when you shop online.\n",
    "\n",
    "{task_description}\n",
    "\"\"\"\n",
    "\n",
    "# Chain of thought approach\n",
    "cot_prompt = f\"\"\"\n",
    "{task_description}\n",
    "\n",
    "Let's break this down step by step:\n",
    "\"\"\"\n",
    "\n",
    "# Role playing approach\n",
    "role_prompt = f\"\"\"\n",
    "You are a friendly science teacher who specializes in making complex technical concepts accessible to middle school students using simple analogies and everyday examples.\n",
    "\n",
    "{task_description}\n",
    "\"\"\"\n",
    "\n",
    "# Combining approaches (Role playing + Chain of thought)\n",
    "combined_prompt = f\"\"\"\n",
    "You are a friendly science teacher who specializes in making complex technical concepts accessible to middle school students using simple analogies and everyday examples.\n",
    "\n",
    "{task_description}\n",
    "\n",
    "Let's break this down step by step with some relatable examples:\n",
    "\"\"\"\n",
    "\n",
    "# Uncomment these to run the comparisons\n",
    "# comparisons = [\n",
    "#     (\"Zero-shot\", zero_shot_prompt),\n",
    "#     (\"Few-shot\", few_shot_prompt),\n",
    "#     (\"Chain of Thought\", cot_prompt),\n",
    "#     (\"Role Playing\", role_prompt),\n",
    "#     (\"Combined Approach\", combined_prompt)\n",
    "# ]\n",
    "\n",
    "# for name, prompt in comparisons:\n",
    "#     response = get_gemini_response(prompt)\n",
    "#     display_prompt_response(prompt, response, f\"{name} Approach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab2aa86",
   "metadata": {},
   "source": [
    "## Additional Resources and References\n",
    "\n",
    "Here are some valuable resources for further exploration of prompt engineering techniques:\n",
    "\n",
    "### Research Papers\n",
    "- Wei, J., Wang, X., Schuurmans, D., et al. (2022). \"[Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)\"\n",
    "- Brown, T. B., Mann, B., Ryder, N., et al. (2020). \"[Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)\"\n",
    "- Kojima, T., Gu, S. S., Reid, M., et al. (2022). \"[Large Language Models are Zero-Shot Reasoners](https://arxiv.org/abs/2205.11916)\"\n",
    "\n",
    "### Guides and Tutorials\n",
    "- [Google's Gemini API Documentation](https://ai.google.dev/gemini-api/docs)\n",
    "- [OpenAI's GPT Best Practices Guide](https://platform.openai.com/docs/guides/prompt-engineering)\n",
    "- [Anthropic's Guide to Prompt Design with Claude](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview#how-to-prompt-engineer)\n",
    "\n",
    "### Community Resources\n",
    "- [Prompt Engineering Guide](https://www.promptingguide.ai/)\n",
    "- [Anthropic's Prompt Engineering Interactive Tutorial](https://github.com/anthropics/prompt-eng-interactive-tutorial)\n",
    "\n",
    "Remember that prompt engineering is an evolving field, and new techniques and best practices continue to emerge as language models and their applications develop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
