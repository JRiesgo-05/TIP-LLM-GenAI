{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "755efdaf",
   "metadata": {},
   "source": [
    "# Prompt Engineering Challenge\n",
    "\n",
    "In this activity, we'll practice improving poorly worded prompts using the prompt engineering techniques we've learned:\n",
    "\n",
    "1. Zero-shot Prompting\n",
    "2. Few-shot Prompting\n",
    "3. Chain of Thought (CoT) Prompting\n",
    "4. Role Playing\n",
    "\n",
    "## Objective\n",
    "\n",
    "You'll be presented with a poorly worded prompt and its unsatisfactory output. Your challenge is to improve the prompt using one or more of the techniques above to get a better response from the language model.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. Review the poorly worded prompt and its output\n",
    "2. Identify issues with the prompt\n",
    "3. Apply prompt engineering techniques to improve it\n",
    "4. Run your improved prompt and compare the results\n",
    "5. Share and discuss which techniques you used and why\n",
    "\n",
    "Let's start by importing the necessary libraries and setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81782f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "\n",
    "# Load environment variables from .env file (if you have any API keys)\n",
    "load_dotenv()\n",
    "\n",
    "# Configure the Google Generative AI API with your API key\n",
    "client = genai.Client(api_key=os.getenv(\"GOOGLE_GENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d10cef7",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Let's create utility functions to interact with the language model and display results consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190a94df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gemini_response(prompt, model=\"gemini-2.0-flash\"):\n",
    "    \"\"\"\n",
    "    Get a response from Google's Gemini model\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The prompt to send to the model\n",
    "        model (str): The model to use (default: gemini-2.0-flash)\n",
    "        \n",
    "    Returns:\n",
    "        str: The model's response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Configure the model\n",
    "        generation_config = {\n",
    "            \"temperature\": 0.2,\n",
    "            \"top_p\": 0.95,\n",
    "            \"top_k\": 40,\n",
    "            \"max_output_tokens\": 1024,\n",
    "        }\n",
    "        \n",
    "        # Generate the response\n",
    "        response = client.models.generate_content(\n",
    "            contents=prompt,\n",
    "            model=model,\n",
    "            config=generation_config,\n",
    "            )\n",
    "        \n",
    "        # Return the response text\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def display_prompt_response(prompt, response, technique=\"\"):\n",
    "    \"\"\"\n",
    "    Display the prompt and response in a formatted way\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The prompt sent to the model\n",
    "        response (str): The model's response\n",
    "        technique (str): The prompt engineering technique used\n",
    "    \"\"\"\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"TECHNIQUE: {technique}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"\\nüìù PROMPT:\")\n",
    "    print(f\"{'-'*80}\")\n",
    "    print(prompt)\n",
    "    print(f\"{'-'*80}\")\n",
    "    print(\"\\nü§ñ RESPONSE:\")\n",
    "    print(f\"{'-'*80}\")\n",
    "    print(response)\n",
    "    print(f\"{'-'*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f1ea3",
   "metadata": {},
   "source": [
    "## Challenge 1: Technical Explanation\n",
    "\n",
    "Here's a poorly worded prompt asking the model to explain a technical concept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b700a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poorly worded prompt\n",
    "poor_prompt_1 = \"\"\"\n",
    "explain neural networks\n",
    "\"\"\"\n",
    "\n",
    "# Get response to the poorly worded prompt\n",
    "response_poor_1 = get_gemini_response(poor_prompt_1)\n",
    "\n",
    "# Display the prompt and response\n",
    "display_prompt_response(poor_prompt_1, response_poor_1, \"Poorly Worded Prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cf1f66",
   "metadata": {},
   "source": [
    "### Issues with this prompt:\n",
    "\n",
    "1. **Lack of specificity**: It doesn't specify what aspects of neural networks to focus on\n",
    "2. **No audience definition**: It doesn't indicate the audience's technical background\n",
    "3. **No format guidance**: It doesn't specify what format the explanation should take\n",
    "4. **No depth indication**: It doesn't indicate how deep the explanation should go\n",
    "5. **No engagement context**: The model doesn't know why the explanation is needed\n",
    "\n",
    "### Your Challenge:\n",
    "\n",
    "Improve this prompt using the prompt engineering techniques you've learned. Below are some suggestions for each technique:\n",
    "\n",
    "#### Zero-shot approach:\n",
    "Add clear instructions about the depth, aspects, audience, and format without examples.\n",
    "\n",
    "#### Few-shot approach:\n",
    "Include examples of good explanations of other technical concepts.\n",
    "\n",
    "#### Chain of Thought approach:\n",
    "Ask the model to explain neural networks step by step, building from simple concepts to complex ones.\n",
    "\n",
    "#### Role Playing approach:\n",
    "Ask the model to adopt a specific persona (e.g., a teacher) to explain neural networks to a specific audience.\n",
    "\n",
    "#### Combined approach:\n",
    "Mix multiple techniques above for an even more effective prompt.\n",
    "\n",
    "Try your improved prompts in the cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5643be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your improved prompt (replace this with your improved version)\n",
    "improved_prompt_1 = \"\"\"\n",
    "# Add your improved prompt here\n",
    "\"\"\"\n",
    "\n",
    "# Get response to your improved prompt\n",
    "# Uncomment the following lines when you're ready to test your improved prompt\n",
    "# response_improved_1 = get_gemini_response(improved_prompt_1)\n",
    "# display_prompt_response(improved_prompt_1, response_improved_1, \"Your Technique Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445c85ac",
   "metadata": {},
   "source": [
    "## Challenge 2: Problem Solving\n",
    "\n",
    "Here's a poorly worded prompt asking the model to solve a problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169f696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poorly worded problem-solving prompt\n",
    "poor_prompt_2 = \"\"\"\n",
    "tennis ball problem: 3 cans, 4 balls in each, half price sale, how much did i save?\n",
    "\"\"\"\n",
    "\n",
    "# Get response to the poorly worded prompt\n",
    "response_poor_2 = get_gemini_response(poor_prompt_2)\n",
    "\n",
    "# Display the prompt and response\n",
    "display_prompt_response(poor_prompt_2, response_poor_2, \"Poorly Worded Prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd8606d",
   "metadata": {},
   "source": [
    "### Issues with this prompt:\n",
    "\n",
    "1. **Incomplete information**: Missing the original price of the tennis balls\n",
    "2. **Ambiguous wording**: \"Half price sale\" could mean different things\n",
    "3. **Poor formatting**: Run-on sentence, informal shorthand\n",
    "4. **No guidance for problem-solving approach**: No request for step-by-step thinking\n",
    "5. **Missing units**: No specification if we're talking about dollar amounts, etc.\n",
    "\n",
    "### Your Challenge:\n",
    "\n",
    "Improve this prompt using the prompt engineering techniques you've learned. Here are some suggestions:\n",
    "\n",
    "#### Zero-shot approach:\n",
    "Clearly state all the needed information and ask for a detailed solution.\n",
    "\n",
    "#### Few-shot approach:\n",
    "Include an example of a similar word problem with a proper solution.\n",
    "\n",
    "#### Chain of Thought approach:\n",
    "Explicitly ask the model to solve the problem step by step.\n",
    "\n",
    "#### Role Playing approach:\n",
    "Ask the model to take on the role of a math teacher explaining the solution clearly.\n",
    "\n",
    "#### Combined approach:\n",
    "Mix multiple techniques for an even better prompt.\n",
    "\n",
    "Try your improved prompts in the cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cca676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your improved prompt (replace this with your improved version)\n",
    "improved_prompt_2 = \"\"\"\n",
    "# Add your improved prompt here\n",
    "\"\"\"\n",
    "\n",
    "# Get response to your improved prompt\n",
    "# Uncomment the following lines when you're ready to test your improved prompt\n",
    "# response_improved_2 = get_gemini_response(improved_prompt_2)\n",
    "# display_prompt_response(improved_prompt_2, response_improved_2, \"Your Technique Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750d71c0",
   "metadata": {},
   "source": [
    "## Challenge 3: Creative Content Generation\n",
    "\n",
    "Here's a poorly worded prompt asking the model to generate creative content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3d36d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poorly worded creative content prompt\n",
    "poor_prompt_3 = \"\"\"\n",
    "write a story about climate change\n",
    "\"\"\"\n",
    "\n",
    "# Get response to the poorly worded prompt\n",
    "response_poor_3 = get_gemini_response(poor_prompt_3)\n",
    "\n",
    "# Display the prompt and response\n",
    "display_prompt_response(poor_prompt_3, response_poor_3, \"Poorly Worded Prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e4c9b6",
   "metadata": {},
   "source": [
    "### Issues with this prompt:\n",
    "\n",
    "1. **Lack of specificity**: No details about the story's length, style, tone, or target audience\n",
    "2. **No creative direction**: No characters, setting, plot, or theme guidance\n",
    "3. **No emotional context**: No indication of the intended emotional impact\n",
    "4. **Generic topic**: \"Climate change\" is extremely broad\n",
    "5. **No format guidance**: No structure or format specifications\n",
    "\n",
    "### Your Challenge:\n",
    "\n",
    "Improve this prompt using the prompt engineering techniques you've learned. Some suggestions:\n",
    "\n",
    "#### Zero-shot approach:\n",
    "Add specific details about the story structure, characters, setting, and tone.\n",
    "\n",
    "#### Few-shot approach:\n",
    "Include a short example of a similar climate-related story to demonstrate the style.\n",
    "\n",
    "#### Chain of Thought approach:\n",
    "Ask the model to develop the story outline before writing the full narrative.\n",
    "\n",
    "#### Role Playing approach:\n",
    "Have the model adopt the persona of an award-winning environmental fiction author.\n",
    "\n",
    "#### Combined approach:\n",
    "Mix multiple techniques for the most effective prompt.\n",
    "\n",
    "Try your improved prompts in the cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c9f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your improved prompt (replace this with your improved version)\n",
    "improved_prompt_3 = \"\"\"\n",
    "# Add your improved prompt here\n",
    "\"\"\"\n",
    "\n",
    "# Get response to your improved prompt\n",
    "# Uncomment the following lines when you're ready to test your improved prompt\n",
    "# response_improved_3 = get_gemini_response(improved_prompt_3)\n",
    "# display_prompt_response(improved_prompt_3, response_improved_3, \"Your Technique Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1b606d",
   "metadata": {},
   "source": [
    "## Reflection and Comparison\n",
    "\n",
    "After completing the challenges, take some time to reflect on the following:\n",
    "\n",
    "1. **Which technique(s) seemed most effective for each type of challenge?**\n",
    "   - Was Chain of Thought particularly useful for the problem-solving task?\n",
    "   - Did Role Playing work better for creative content?\n",
    "   - Was Few-shot learning helpful for the technical explanation?\n",
    "\n",
    "2. **What specific improvements made the biggest difference?**\n",
    "   - Adding more context?\n",
    "   - Specifying the format?\n",
    "   - Breaking down complex tasks?\n",
    "   - Defining the audience?\n",
    "\n",
    "3. **What patterns did you notice in your improved prompts?**\n",
    "   - Did you tend to make them longer?\n",
    "   - Did you add more structure?\n",
    "   - Did you include specific instructions about tone or style?\n",
    "\n",
    "## Summary of Prompt Engineering Techniques\n",
    "\n",
    "| Technique | Best For | Key Elements to Include |\n",
    "|-----------|----------|-------------------------|\n",
    "| Zero-shot | Simple, straightforward tasks | Clear instructions, specific format, audience definition |\n",
    "| Few-shot | Tasks requiring specific patterns | Representative examples, consistent formats between examples and task |\n",
    "| Chain of Thought | Complex reasoning, multi-step problems | \"Think step by step\" instruction, breaking down the problem |\n",
    "| Role Playing | Specialized knowledge, consistent tone | Specific persona, expertise level, audience |\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "As you continue working with LLMs, keep experimenting with these prompt engineering techniques. The best approach often depends on:\n",
    "- The specific task\n",
    "- The model you're using\n",
    "- The desired output format and style\n",
    "- The complexity of the problem\n",
    "\n",
    "Remember that prompt engineering is an iterative process‚Äîcontinue refining your prompts based on the responses you receive!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tip-llm-genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
